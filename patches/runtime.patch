diff --git a/mlir/lib/Conversion/GPUCommon/ConvertLaunchFuncToRuntimeCalls.cpp b/mlir/lib/Conversion/GPUCommon/ConvertLaunchFuncToRuntimeCalls.cpp
index 14011e08de0..bf879e20d75 100644
--- a/mlir/lib/Conversion/GPUCommon/ConvertLaunchFuncToRuntimeCalls.cpp
+++ b/mlir/lib/Conversion/GPUCommon/ConvertLaunchFuncToRuntimeCalls.cpp
@@ -42,6 +42,8 @@ static constexpr const char *kGpuLaunchKernelName = "mgpuLaunchKernel";
 static constexpr const char *kGpuStreamCreateName = "mgpuStreamCreate";
 static constexpr const char *kGpuStreamSynchronizeName =
     "mgpuStreamSynchronize";
+static constexpr const char *kGpuMemAllocName = "mgpuMemAlloc";
+static constexpr const char *kGpuMemFreeName = "mgpuMemFree";
 static constexpr const char *kGpuMemHostRegisterName = "mgpuMemHostRegister";
 static constexpr const char *kGpuBinaryStorageSuffix = "_gpubin_cst";
 
@@ -108,6 +110,24 @@ private:
                                           /*alignment=*/0);
   }
 
+  // Truncate an index value type to unsigned int if necessary.
+  Value truncateIndex(OpBuilder &builder, Location loc, Value value) {
+    auto llvmType = value.getType().cast<LLVM::LLVMType>();
+    if (llvmType.getIntegerBitWidth() > 32) {
+      return builder.create<LLVM::TruncOp>(loc, getInt32Type(), value);
+    }
+    return value;
+  }
+
+  // Extend an index value type to a size type if necessary,
+  Value extendIndex(OpBuilder &builder, Location loc, Value value) {
+    auto llvmType = value.getType().cast<LLVM::LLVMType>();
+    if (llvmType.getIntegerBitWidth() < 64) {
+      return builder.create<LLVM::ZExtOp>(loc, getInt64Type(), value);
+    }
+    return value;
+  }
+
   void declareGpuRuntimeFunctions(Location loc);
   void addParamToList(OpBuilder &builder, Location loc, Value param, Value list,
                       unsigned pos, Value one);
@@ -115,6 +135,7 @@ private:
   Value generateKernelNameConstant(StringRef moduleName, StringRef name,
                                    Location loc, OpBuilder &builder);
   void translateGpuLaunchCalls(mlir::gpu::LaunchFuncOp launchOp);
+  void replaceMallocAndFreeCalls(LLVM::CallOp callOp);
 
 public:
   GpuLaunchFuncToGpuRuntimeCallsPass() = default;
@@ -132,6 +153,22 @@ public:
     getOperation().walk(
         [this](mlir::gpu::LaunchFuncOp op) { translateGpuLaunchCalls(op); });
 
+    // Allocate and free device memory instead of host memory.
+    getOperation().walk(
+        [this](LLVM::CallOp op) { replaceMallocAndFreeCalls(op); });
+
+    // Erase the malloc and free function declarations if they are unused.
+    if (llvm::none_of(getOperation().getOps<LLVM::CallOp>(),
+                      [](LLVM::CallOp callOp) {
+                        return callOp.callee().getValueOr("") == "malloc" ||
+                               callOp.callee().getValueOr("") == "free";
+                      })) {
+      if (auto *malloc = getOperation().lookupSymbol("malloc"))
+        malloc->erase();
+      if (auto *free = getOperation().lookupSymbol("free"))
+        free->erase();
+    }
+
     // GPU kernel modules are no longer necessary since we have a global
     // constant with the CUBIN, or HSACO data.
     for (auto m :
@@ -189,12 +226,12 @@ void GpuLaunchFuncToGpuRuntimeCallsPass::declareGpuRuntimeFunctions(
             getVoidType(),
             {
                 getPointerType(),        /* void* f */
-                getIntPtrType(),         /* intptr_t gridXDim */
-                getIntPtrType(),         /* intptr_t gridyDim */
-                getIntPtrType(),         /* intptr_t gridZDim */
-                getIntPtrType(),         /* intptr_t blockXDim */
-                getIntPtrType(),         /* intptr_t blockYDim */
-                getIntPtrType(),         /* intptr_t blockZDim */
+                getInt32Type(),          /* unsigned int gridXDim */
+                getInt32Type(),          /* unsigned int gridyDim */
+                getInt32Type(),          /* unsigned int gridZDim */
+                getInt32Type(),          /* unsigned int blockXDim */
+                getInt32Type(),          /* unsigned int blockYDim */
+                getInt32Type(),          /* unsigned int blockZDim */
                 getInt32Type(),          /* unsigned int sharedMemBytes */
                 getPointerType(),        /* void *hstream */
                 getPointerPointerType(), /* void **kernelParams */
@@ -216,6 +253,24 @@ void GpuLaunchFuncToGpuRuntimeCallsPass::declareGpuRuntimeFunctions(
                                       {getPointerType()}, /* void *stream */
                                       /*isVarArg=*/false));
   }
+  if (!module.lookupSymbol(kGpuMemAllocName)) {
+    builder.create<LLVM::LLVMFuncOp>(
+        loc, kGpuMemAllocName,
+        LLVM::LLVMType::getFunctionTy(
+            getVoidType(),
+            {
+                getPointerPointerType(), /* void **ptr */
+                getInt64Type()           /* int64 sizeBytes */
+            },
+            /*isVarArg=*/false));
+  }
+  if (!module.lookupSymbol(kGpuMemFreeName)) {
+    builder.create<LLVM::LLVMFuncOp>(
+        loc, kGpuMemFreeName,
+        LLVM::LLVMType::getFunctionTy(getVoidType(),
+                                      getPointerType(), /* void *ptr */
+                                      /*isVarArg=*/false));
+  }
   if (!module.lookupSymbol(kGpuMemHostRegisterName)) {
     builder.create<LLVM::LLVMFuncOp>(
         loc, kGpuMemHostRegisterName,
@@ -413,6 +468,12 @@ void GpuLaunchFuncToGpuRuntimeCallsPass::translateGpuLaunchCalls(
   // Invoke the function with required arguments.
   auto gpuLaunchKernel =
       getOperation().lookupSymbol<LLVM::LLVMFuncOp>(kGpuLaunchKernelName);
+  auto gridSizeX = truncateIndex(builder, loc, launchOp.gridSizeX());
+  auto gridSizeY = truncateIndex(builder, loc, launchOp.gridSizeY());
+  auto gridSizeZ = truncateIndex(builder, loc, launchOp.gridSizeZ());
+  auto blockSizeX = truncateIndex(builder, loc, launchOp.blockSizeX());
+  auto blockSizeY = truncateIndex(builder, loc, launchOp.blockSizeY());
+  auto blockSizeZ = truncateIndex(builder, loc, launchOp.blockSizeZ());
   auto paramsArray = setupParamsArray(launchOp, builder);
   if (!paramsArray) {
     launchOp.emitOpError() << "cannot pass given parameters to the kernel";
@@ -420,25 +481,57 @@ void GpuLaunchFuncToGpuRuntimeCallsPass::translateGpuLaunchCalls(
   }
   auto nullpointer =
       builder.create<LLVM::IntToPtrOp>(loc, getPointerPointerType(), zero);
-  builder.create<LLVM::CallOp>(
-      loc, ArrayRef<Type>{getVoidType()},
-      builder.getSymbolRefAttr(gpuLaunchKernel),
-      ArrayRef<Value>{function.getResult(0), launchOp.getOperand(0),
-                      launchOp.getOperand(1), launchOp.getOperand(2),
-                      launchOp.getOperand(3), launchOp.getOperand(4),
-                      launchOp.getOperand(5), zero, /* sharedMemBytes */
-                      stream.getResult(0),          /* stream */
-                      paramsArray,                  /* kernel params */
-                      nullpointer /* extra */});
-  // Sync on the stream to make it synchronous.
+  builder.create<LLVM::CallOp>(loc, ArrayRef<Type>{},
+                               builder.getSymbolRefAttr(gpuLaunchKernel),
+                               ArrayRef<Value>{function.getResult(0), gridSizeX,
+                                               gridSizeY, gridSizeZ, blockSizeX,
+                                               blockSizeY, blockSizeZ,
+                                               zero, /* sharedMemBytes */
+                                               stream.getResult(0), /* stream */
+                                               paramsArray, /* kernel params */
+                                               nullpointer /* extra */});
   auto gpuStreamSync =
       getOperation().lookupSymbol<LLVM::LLVMFuncOp>(kGpuStreamSynchronizeName);
-  builder.create<LLVM::CallOp>(loc, ArrayRef<Type>{getVoidType()},
+  builder.create<LLVM::CallOp>(loc, ArrayRef<Type>{},
                                builder.getSymbolRefAttr(gpuStreamSync),
                                ArrayRef<Value>(stream.getResult(0)));
   launchOp.erase();
 }
 
+// Replace all malloc and free pairs by GPU memory allocations.
+void GpuLaunchFuncToGpuRuntimeCallsPass::replaceMallocAndFreeCalls(
+    LLVM::CallOp callOp) {
+  // Replace all memory allocations by GPU memory allocations or frees.
+  if (callOp.callee().getValueOr("") == "malloc" ||
+      callOp.callee().getValueOr("") == "free") {
+    OpBuilder builder(callOp);
+    Location loc = callOp.getLoc();
+
+    if (callOp.callee().getValue() == "malloc") {
+      auto one = builder.create<LLVM::ConstantOp>(loc, getInt64Type(),
+                                                  builder.getI64IntegerAttr(1));
+      auto allocPtr =
+          builder.create<LLVM::AllocaOp>(loc, getPointerPointerType(), one, 0);
+      auto allocFunc =
+          getOperation().lookupSymbol<LLVM::LLVMFuncOp>(kGpuMemAllocName);
+      auto size = extendIndex(builder, loc, callOp.getOperand(0));
+      builder.create<LLVM::CallOp>(loc, ArrayRef<Type>{},
+                                   builder.getSymbolRefAttr(allocFunc),
+                                   ArrayRef<Value>{allocPtr, size});
+      callOp.getResult(0).replaceAllUsesWith(
+          builder.create<LLVM::LoadOp>(loc, getPointerType(), allocPtr));
+    }
+    if (callOp.callee().getValue() == "free") {
+      auto freeFunc =
+          getOperation().lookupSymbol<LLVM::LLVMFuncOp>(kGpuMemFreeName);
+      builder.create<LLVM::CallOp>(loc, ArrayRef<Type>{},
+                                   builder.getSymbolRefAttr(freeFunc),
+                                   ArrayRef<Value>{callOp.getOperand(0)});
+    }
+    callOp.erase();
+  }
+}
+
 std::unique_ptr<mlir::OperationPass<mlir::ModuleOp>>
 mlir::createConvertGpuLaunchFuncToGpuRuntimeCallsPass(
     StringRef gpuBinaryAnnotation) {
diff --git a/mlir/tools/mlir-cuda-runner/cuda-runtime-wrappers.cpp b/mlir/tools/mlir-cuda-runner/cuda-runtime-wrappers.cpp
index 8e2dc029fa9..8606373737a 100644
--- a/mlir/tools/mlir-cuda-runner/cuda-runtime-wrappers.cpp
+++ b/mlir/tools/mlir-cuda-runner/cuda-runtime-wrappers.cpp
@@ -17,6 +17,7 @@
 
 #include "mlir/ExecutionEngine/CRunnerUtils.h"
 #include "llvm/ADT/ArrayRef.h"
+#include "llvm/ADT/DenseMap.h"
 #include "llvm/Support/raw_ostream.h"
 
 #include "cuda.h"
@@ -32,6 +33,74 @@
     llvm::errs() << "'" << #expr << "' failed with '" << name << "'\n";        \
   }(expr)
 
+namespace {
+// Context object that buffers GPU modules, functions, temporary storage.
+struct Runtime {
+  // Load a module and cache it.
+  void loadModule(CUmodule *module, void *data) {
+    int32_t err = CUDA_SUCCESS;
+    // Load the module during the first execution.
+    if(moduleList.count(data) == 0) {
+      CUDA_REPORT_IF_ERROR(cuModuleLoadData(module, data));
+      moduleList[data] = *module;
+    }
+    *module = moduleList[data];
+  }
+
+  // Get a function an cache it.
+  void getFunction(CUfunction *function, CUmodule module, const char *name) {
+    // Get the function during the first execution.
+    if(functionList.count(name) == 0) {
+      CUDA_REPORT_IF_ERROR(cuModuleGetFunction(function, module, name));
+      functionList[name] = *function;
+    }
+    *function = functionList[name];
+  }
+
+  // Get the default stream.
+  void createStream(CUstream *stream) {
+    if(streamList.empty()) {
+      CUstream stream;
+      CUDA_REPORT_IF_ERROR(cuStreamCreate(&stream, CU_STREAM_DEFAULT));
+      streamList.push_back(stream);
+    }
+    *stream = streamList.back();
+  }
+
+  // Allocate GPU device memory.
+  void allocMem(CUdeviceptr *ptr, size_t size) {
+    // Allocate storage if free list contains no matching allocation.
+    if(tempList.count(size) == 0 || tempList[size].empty()) {
+      CUDA_REPORT_IF_ERROR(cuMemAlloc(ptr, size));
+      return;
+    }
+    // Return existing allocation.
+    *ptr = tempList[size].back();
+    tempList[size].pop_back();
+  }
+
+  // Free GPU device memory.
+  void freeMem(CUdeviceptr ptr) {
+    CUdeviceptr allocPtr;
+    size_t allocSize = 0;
+    // Get the size of the allocation.
+    CUDA_REPORT_IF_ERROR(cuMemGetAddressRange(&allocPtr, &allocSize, ptr));
+    tempList[allocSize].push_back(ptr);
+  }
+
+  static Runtime &getInstance() {
+    thread_local Runtime runtime;
+    return runtime;
+  }
+
+private:
+  std::vector<CUstream> streamList;
+  llvm::DenseMap<void*, CUmodule> moduleList;
+  llvm::DenseMap<const char*, CUfunction> functionList;
+  llvm::DenseMap<size_t, std::vector<CUdeviceptr>> tempList;
+};
+} // anonymous namespace
+
 extern "C" CUmodule mgpuModuleLoad(void *data) {
   CUmodule module = nullptr;
   CUDA_REPORT_IF_ERROR(cuModuleLoadData(&module, data));
@@ -59,7 +128,7 @@ extern "C" void mgpuLaunchKernel(CUfunction function, intptr_t gridX,
 
 extern "C" CUstream mgpuStreamCreate() {
   CUstream stream = nullptr;
-  CUDA_REPORT_IF_ERROR(cuStreamCreate(&stream, CU_STREAM_NON_BLOCKING));
+  Runtime::getInstance().createStream(&stream);
   return stream;
 }
 
@@ -67,6 +136,14 @@ extern "C" void mgpuStreamSynchronize(CUstream stream) {
   CUDA_REPORT_IF_ERROR(cuStreamSynchronize(stream));
 }
 
+extern "C" void mgpuMemAlloc(CUdeviceptr *ptr, uint64_t size) {
+  Runtime::getInstance().allocMem(ptr, size);
+}
+
+extern "C" void mgpuMemFree(CUdeviceptr ptr) {
+  Runtime::getInstance().freeMem(ptr);
+}
+
 /// Helper functions for writing mlir example code
 
 // Allows to register byte array with the CUDA runtime. Helpful until we have
diff --git a/mlir/tools/mlir-rocm-runner/rocm-runtime-wrappers.cpp b/mlir/tools/mlir-rocm-runner/rocm-runtime-wrappers.cpp
index b97ce695ac4..1da606e488b 100644
--- a/mlir/tools/mlir-rocm-runner/rocm-runtime-wrappers.cpp
+++ b/mlir/tools/mlir-rocm-runner/rocm-runtime-wrappers.cpp
@@ -17,6 +17,7 @@
 
 #include "mlir/ExecutionEngine/CRunnerUtils.h"
 #include "llvm/ADT/ArrayRef.h"
+#include "llvm/ADT/DenseMap.h"
 #include "llvm/Support/raw_ostream.h"
 
 #include "hip/hip_runtime.h"
@@ -25,23 +26,89 @@
   [](hipError_t result) {                                                      \
     if (!result)                                                               \
       return;                                                                  \
-    const char *name = nullptr;                                                \
-    hipGetErrorName(result, &name);                                            \
+    const char *name = hipGetErrorName(result);                                         \
     if (!name)                                                                 \
       name = "<unknown>";                                                      \
     llvm::errs() << "'" << #expr << "' failed with '" << name << "'\n";        \
   }(expr)
 
+namespace {
+// Context object that buffers GPU modules, functions, temporary storage.
+struct Runtime {
+  // Load a module and cache it.
+  void loadModule(hipModule_t *module, void *data) {
+    // Load the module during the first execution.
+    if(moduleList.count(data) == 0) {
+      HIP_REPORT_IF_ERROR(hipModuleLoadData(module, data));
+      moduleList[data] = *module;
+    }
+    *module = moduleList[data];
+  }
+
+  // Get a function an cache it.
+  void getFunction(hipFunction_t *function, hipModule_t module, const char *name) {
+    // Get the function during the first execution.
+    if(functionList.count(name) == 0) {
+      HIP_REPORT_IF_ERROR(hipModuleGetFunction(function, module, name));
+      functionList[name] = *function;
+    }
+    *function = functionList[name];
+  }
+
+  // Get the default stream.
+  void createStream(hipStream_t *stream) {
+    if(streamList.empty()) {
+      hipStream_t stream;
+      HIP_REPORT_IF_ERROR(hipStreamCreate(&stream));
+      streamList.push_back(stream);
+    }
+    *stream = streamList.back();
+  }
+
+  // Allocate GPU device memory.
+  void allocMem(hipDeviceptr_t *ptr, size_t size) {
+    // Allocate storage if free list contains no matching allocation.
+    if(tempList.count(size) == 0 || tempList[size].empty()) {
+      HIP_REPORT_IF_ERROR(hipMalloc(ptr, size));
+      return;
+    }
+    // Return existing allocation.
+    *ptr = tempList[size].back();
+    tempList[size].pop_back();
+  }
+
+  // Free GPU device memory.
+  void freeMem(hipDeviceptr_t ptr) {
+    hipDeviceptr_t allocPtr;
+    size_t allocSize = 0;
+    // Get the size of the allocation.
+    HIP_REPORT_IF_ERROR(hipMemGetAddressRange(&allocPtr, &allocSize, ptr));
+    tempList[allocSize].push_back(ptr);
+  }
+
+  static Runtime &getInstance() {
+    thread_local Runtime runtime;
+    return runtime;
+  }
+
+private:
+  std::vector<hipStream_t> streamList;
+  llvm::DenseMap<void*, hipModule_t> moduleList;
+  llvm::DenseMap<const char*, hipFunction_t> functionList;
+  llvm::DenseMap<size_t, std::vector<hipDeviceptr_t>> tempList;
+};
+} // anonymous namespace
+
 extern "C" hipModule_t mgpuModuleLoad(void *data) {
   hipModule_t module = nullptr;
-  HIP_REPORT_IF_ERROR(hipModuleLoadData(&module, data));
+  Runtime::getInstance().loadModule(&module, data);
   return module;
 }
 
 extern "C" hipFunction_t mgpuModuleGetFunction(hipModule_t module,
                                                const char *name) {
   hipFunction_t function = nullptr;
-  HIP_REPORT_IF_ERROR(hipModuleGetFunction(&function, module, name));
+  Runtime::getInstance().getFunction(&function, module, name);
   return function;
 }
 
@@ -61,7 +128,7 @@ extern "C" void mgpuLaunchKernel(hipFunction_t function, intptr_t gridX,
 
 extern "C" void *mgpuStreamCreate() {
   hipStream_t stream = nullptr;
-  HIP_REPORT_IF_ERROR(hipStreamCreate(&stream));
+  Runtime::getInstance().createStream(&stream);
   return stream;
 }
 
@@ -69,13 +136,20 @@ extern "C" void mgpuStreamSynchronize(hipStream_t stream) {
   return HIP_REPORT_IF_ERROR(hipStreamSynchronize(stream));
 }
 
+extern "C" void mgpuMemAlloc(hipDeviceptr_t *ptr, uint64_t size) {
+  Runtime::getInstance().allocMem(ptr, size);
+}
+
+extern "C" void mgpuMemFree(hipDeviceptr_t ptr) {
+  Runtime::getInstance().freeMem(ptr);
+}
+
 /// Helper functions for writing mlir example code
 
 // Allows to register byte array with the ROCM runtime. Helpful until we have
 // transfer functions implemented.
 extern "C" void mgpuMemHostRegister(void *ptr, uint64_t sizeBytes) {
-  HIP_REPORT_IF_ERROR(hipHostRegister(ptr, sizeBytes, /*flags=*/0),
-                      "MemHostRegister");
+  HIP_REPORT_IF_ERROR(hipHostRegister(ptr, sizeBytes, /*flags=*/0));
 }
 
 // Allows to register a MemRef with the ROCM runtime. Initializes array with
@@ -116,10 +190,9 @@ extern "C" void mgpuMemHostRegisterInt32(int64_t rank, void *ptr) {
 
 template <typename T>
 void mgpuMemGetDevicePointer(T *hostPtr, T **devicePtr) {
-  HIP_REPORT_IF_ERROR(hipSetDevice(0), "hipSetDevice");
+  HIP_REPORT_IF_ERROR(hipSetDevice(0));
   HIP_REPORT_IF_ERROR(
-      hipHostGetDevicePointer((void **)devicePtr, hostPtr, /*flags=*/0),
-      "hipHostGetDevicePointer");
+      hipHostGetDevicePointer((void **)devicePtr, hostPtr, /*flags=*/0));
 }
 
 extern "C" StridedMemRefType<float, 1>
